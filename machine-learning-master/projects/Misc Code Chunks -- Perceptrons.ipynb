{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if weight1 + weight2 = 2.0 and bias= -1.1, difference is about 0.9 (ignoring the negative sign). so adjust the weights in a way the difference is as small as 0.9, you can also toy with the negative sign, by placing it beside weight 1 or 2 or bias or 1&bias or 1&2 or 2&bias, you get the gist, right. Apply theory as intuition leads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      "Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "      0          0                  -1.1                    0          Yes\n",
      "      0          1                  -0.1                    0          Yes\n",
      "      1          0                  -0.1                    0          Yes\n",
      "      1          1                   0.9                    1          Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: Set weight1, weight2, and bias\n",
    "weight1 = 1.0\n",
    "weight2 = 1.0\n",
    "bias = -1.1\n",
    "\n",
    "\n",
    "# DON'T CHANGE ANYTHING BELOW\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [False, False, False, True]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are two ways to go from an AND perceptron to an OR perceptron?\n",
    "\n",
    "Increase the weights && Decrease the magnitude of the bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " calculate the NOT operation on the second input and ignores the first input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      "Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "      0          0                   0.5                    1          Yes\n",
      "      0          1                  -1.5                    0          Yes\n",
      "      1          0                   1.5                    1          Yes\n",
      "      1          1                  -0.5                    0          Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: Set weight1, weight2, and bias\n",
    "weight1 = 1.0\n",
    "weight2 = -2.0\n",
    "bias = .5\n",
    "\n",
    "\n",
    "# DON'T CHANGE ANYTHING BELOW\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [True, False, True, False]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$w_1x_1 + w_2x_2 + b = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `test_input=(0,0)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$weight_1 = 0$$\n",
    "$$weight_1 = -2$$\n",
    "$$bias = 0.5$$\n",
    "$$x_1 = 0$$\n",
    "$$x_2 = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$0*0 + -2*0 + 0.5 = .5$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percepton Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rf. 14.9, in which they graph the boundary lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Setting the random seed, feel free to change it and see different solutions.\n",
    "np.random.seed(42)\n",
    "\n",
    "def stepFunction(t):\n",
    "    if t >= 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def prediction(X, W, b):\n",
    "    return stepFunction((np.matmul(X,W)+b)[0])\n",
    "\n",
    "# TODO: Fill in the code below to implement the perceptron trick.\n",
    "# The function should receive as inputs the data X, the labels y,\n",
    "# the weights W (as an array), and the bias b,\n",
    "# update the weights and bias W, b, according to the perceptron algorithm,\n",
    "# and return W and b.\n",
    "def perceptronStep(X, y, W, b, learn_rate = 0.01):\n",
    "    # Fill in code\n",
    "    for i in range(len(X)):\n",
    "        y_hat = prediction(X[i], W, b)\n",
    "        if y[i]-y_hat == 1:\n",
    "            W[0] += X[i][0]*learn_rate\n",
    "            W[1] += X[i][1]*learn_rate\n",
    "            b += learn_rate\n",
    "            print(W[0], W[1], b)\n",
    "        elif y[i]-y_hat == -1:\n",
    "            W[0] -= X[i][0]*learn_rate\n",
    "            W[1] -= X[i][1]*learn_rate\n",
    "            b -= learn_rate\n",
    "            print(W[0], W[1], b)\n",
    "    return W, b\n",
    "    \n",
    "# This function runs the perceptron algorithm repeatedly on the dataset,\n",
    "# and returns a few of the boundary lines obtained in the iterations,\n",
    "# for plotting purposes.\n",
    "# Feel free to play with the learning rate and the num_epochs,\n",
    "# and see your results plotted below.\n",
    "def trainPerceptronAlgorithm(X, y, learn_rate = 0.01, num_epochs = 25):\n",
    "    x_min, x_max = min(X.T[0]), max(X.T[0])\n",
    "    y_min, y_max = min(X.T[1]), max(X.T[1])\n",
    "    W = np.array(np.random.rand(2,1))\n",
    "    b = np.random.rand(1)[0] + x_max\n",
    "    # These are the solution lines that get plotted below.\n",
    "    boundary_lines = []\n",
    "    for i in range(num_epochs):\n",
    "        # In each epoch, we apply the perceptron step.\n",
    "        W, b = perceptronStep(X, y, W, b, learn_rate)\n",
    "        boundary_lines.append((-W[0]/W[1], -b/W[1]))\n",
    "    return boundary_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray(pd.read_csv('data_percepton.csv', header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = data[:,0:2]\n",
    "y_data =data[:,2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05255061] [0.85617615] 1.5911150117432087\n",
      "[0.04812321] [0.85025565] 1.5811150117432087\n",
      "[0.03960561] [0.84364365] 1.5711150117432087\n",
      "[0.03356201] [0.83498315] 1.5611150117432087\n",
      "[0.02673771] [0.83015305] 1.5511150117432086\n",
      "[0.01673771] [0.82247155] 1.5411150117432086\n",
      "[0.00943881] [0.81436455] 1.5311150117432086\n",
      "[0.00270111] [0.80656705] 1.5211150117432086\n",
      "[-0.00517499] [0.80074935] 1.5111150117432086\n",
      "[-0.01231919] [0.79308135] 1.5011150117432086\n",
      "[-0.01725709] [0.78765875] 1.4911150117432086\n",
      "[-0.02515449] [0.78023545] 1.4811150117432086\n",
      "[-0.03194499] [0.77414335] 1.4711150117432086\n",
      "[-0.03858699] [0.76689145] 1.4611150117432086\n",
      "[-0.04652659] [0.76121255] 1.4511150117432086\n",
      "[-0.05360239] [0.75361035] 1.4411150117432086\n",
      "[-0.05954449] [0.74742465] 1.4311150117432085\n",
      "[-0.06448089] [0.74180225] 1.4211150117432085\n",
      "[-0.07225159] [0.73829975] 1.4111150117432085\n",
      "[-0.08023009] [0.73060765] 1.4011150117432085\n",
      "[-0.08731769] [0.72093125] 1.3911150117432085\n",
      "[-0.09423529] [0.71484475] 1.3811150117432085\n",
      "[-0.10087609] [0.70563725] 1.3711150117432085\n",
      "[-0.10747339] [0.69897065] 1.3611150117432085\n",
      "[-0.11393079] [0.69328615] 1.3511150117432085\n",
      "[-0.12289469] [0.68620115] 1.3411150117432085\n",
      "[-0.13144229] [0.67988445] 1.3311150117432085\n",
      "[-0.13765139] [0.67184205] 1.3211150117432084\n",
      "[-0.14555709] [0.66623125] 1.3111150117432084\n",
      "[-0.15145059] [0.65907305] 1.3011150117432084\n",
      "[-0.15713519] [0.65166705] 1.2911150117432084\n",
      "[-0.16372639] [0.64451225] 1.2811150117432084\n",
      "[-0.17082019] [0.63710815] 1.2711150117432084\n",
      "[-0.17673559] [0.63081545] 1.2611150117432084\n",
      "[-0.18131849] [0.62617445] 1.2511150117432084\n",
      "[-0.18931669] [0.61868975] 1.2411150117432084\n",
      "[-0.19541409] [0.61321405] 1.2311150117432084\n",
      "[-0.20222679] [0.60451555] 1.2211150117432084\n",
      "[-0.20989619] [0.59804195] 1.2111150117432083\n",
      "[-0.21680099] [0.58973615] 1.2011150117432083\n",
      "[-0.22361319] [0.58008205] 1.1911150117432083\n",
      "[-0.23093609] [0.57365755] 1.1811150117432083\n",
      "[-0.23855059] [0.56764375] 1.1711150117432083\n",
      "[-0.24444909] [0.55894825] 1.1611150117432083\n",
      "[-0.25176359] [0.55149665] 1.1511150117432083\n",
      "[-0.25946649] [0.54448265] 1.1411150117432083\n",
      "[-0.26678209] [0.53730445] 1.1311150117432083\n",
      "[-0.27123769] [0.53150535] 1.1211150117432083\n",
      "[-0.27976519] [0.52290665] 1.1111150117432083\n",
      "[-0.28495639] [0.51667075] 1.1011150117432082\n",
      "[-0.29048939] [0.50667075] 1.0911150117432082\n",
      "[-0.29491679] [0.50075025] 1.0811150117432082\n",
      "[-0.30343439] [0.49413825] 1.0711150117432082\n",
      "[-0.30947799] [0.48547775] 1.0611150117432082\n",
      "[-0.31630229] [0.48064765] 1.0511150117432082\n",
      "[-0.32630229] [0.47296615] 1.0411150117432082\n",
      "[-0.33360119] [0.46485915] 1.0311150117432082\n",
      "[-0.34033889] [0.45706165] 1.0211150117432082\n",
      "[-0.34821499] [0.45124395] 1.0111150117432082\n",
      "[-0.35535919] [0.44357595] 1.0011150117432082\n",
      "[-0.36029709] [0.43815335] 0.9911150117432082\n",
      "[-0.36819449] [0.43073005] 0.9811150117432081\n",
      "[-0.37498499] [0.42463795] 0.9711150117432081\n",
      "[-0.38162699] [0.41738605] 0.9611150117432081\n",
      "[-0.38956659] [0.41170715] 0.9511150117432081\n",
      "[-0.39664239] [0.40410495] 0.9411150117432081\n",
      "[-0.40258449] [0.39791925] 0.9311150117432081\n",
      "[-0.40752089] [0.39229685] 0.9211150117432081\n",
      "[-0.41529159] [0.38879435] 0.9111150117432081\n",
      "[-0.42327009] [0.38110225] 0.9011150117432081\n",
      "[-0.43035769] [0.37142585] 0.8911150117432081\n",
      "[-0.43727529] [0.36533935] 0.881115011743208\n",
      "[-0.44391609] [0.35613185] 0.871115011743208\n",
      "[-0.45051339] [0.34946525] 0.861115011743208\n",
      "[-0.45697079] [0.34378075] 0.851115011743208\n",
      "[-0.46593469] [0.33669575] 0.841115011743208\n",
      "[-0.47448229] [0.33037905] 0.831115011743208\n",
      "[-0.48069139] [0.32233665] 0.821115011743208\n",
      "[-0.48859709] [0.31672585] 0.811115011743208\n",
      "[-0.49449059] [0.30956765] 0.801115011743208\n",
      "[-0.50017519] [0.30216165] 0.791115011743208\n",
      "[-0.50676639] [0.29500685] 0.781115011743208\n",
      "[-0.51386019] [0.28760275] 0.771115011743208\n",
      "[-0.51977559] [0.28131005] 0.761115011743208\n",
      "[-0.52435849] [0.27666905] 0.7511150117432079\n",
      "[-0.53235669] [0.26918435] 0.7411150117432079\n",
      "[-0.53845409] [0.26370865] 0.7311150117432079\n",
      "[-0.54526679] [0.25501015] 0.7211150117432079\n",
      "[-0.55293619] [0.24853655] 0.7111150117432079\n",
      "[-0.55984099] [0.24023075] 0.7011150117432079\n",
      "[-0.56665319] [0.23057665] 0.6911150117432079\n",
      "[-0.57397609] [0.22415215] 0.6811150117432079\n",
      "[-0.58159059] [0.21813835] 0.6711150117432079\n",
      "[-0.58748909] [0.20944285] 0.6611150117432079\n",
      "[-0.59480359] [0.20199125] 0.6511150117432078\n",
      "[-0.60250649] [0.19497725] 0.6411150117432078\n",
      "[-0.60982209] [0.18779905] 0.6311150117432078\n",
      "[-0.61427769] [0.18199995] 0.6211150117432078\n",
      "[-0.62280519] [0.17340125] 0.6111150117432078\n",
      "[-0.62799639] [0.16716535] 0.6011150117432078\n",
      "[-0.63352939] [0.15716535] 0.5911150117432078\n",
      "[-0.63795679] [0.15124485] 0.5811150117432078\n",
      "[-0.64647439] [0.14463285] 0.5711150117432078\n",
      "[-0.65251799] [0.13597235] 0.5611150117432078\n",
      "[-0.65934229] [0.13114225] 0.5511150117432078\n",
      "[-0.66664119] [0.12303525] 0.5411150117432078\n",
      "[-0.67337889] [0.11523775] 0.5311150117432077\n",
      "[-0.68125499] [0.10942005] 0.5211150117432077\n",
      "[-0.68839919] [0.10175205] 0.5111150117432077\n",
      "[-0.69333709] [0.09632945] 0.5011150117432077\n",
      "[-0.70123449] [0.08890615] 0.4911150117432077\n",
      "[-0.70802499] [0.08281405] 0.4811150117432077\n",
      "[-0.71466699] [0.07556215] 0.4711150117432077\n",
      "[-0.72174279] [0.06795995] 0.4611150117432077\n",
      "[-0.72768489] [0.06177425] 0.4511150117432077\n",
      "[-0.73262129] [0.05615185] 0.44111501174320766\n",
      "[-0.73926209] [0.04694435] 0.43111501174320765\n",
      "[-0.74547119] [0.03890195] 0.42111501174320765\n",
      "[-0.75136469] [0.03174375] 0.41111501174320764\n",
      "[-0.75704929] [0.02433775] 0.40111501174320763\n",
      "[-0.76163219] [0.01969675] 0.3911150117432076\n",
      "[-0.76608779] [0.01389765] 0.3811150117432076\n",
      "[-0.75828269] [0.01326096] 0.3911150117432076\n",
      "[-0.75129199] [0.01699166] 0.40111501174320763\n",
      "[-0.74458419] [0.02164546] 0.41111501174320764\n",
      "[-0.75011719] [0.01164546] 0.40111501174320763\n",
      "[-0.75454459] [0.00572496] 0.3911150117432076\n",
      "[-0.75948249] [0.00030236] 0.3811150117432076\n",
      "[-0.76441889] [-0.00532004] 0.3711150117432076\n",
      "[-0.76900179] [-0.00996104] 0.3611150117432076\n",
      "[-0.77345739] [-0.01576014] 0.3511150117432076\n",
      "[-0.76565229] [-0.01639683] 0.3611150117432076\n",
      "[-0.76056009] [-0.01287123] 0.3711150117432076\n",
      "[-0.75560379] [-0.01072673] 0.3811150117432076\n",
      "[-0.74861309] [-0.00699603] 0.3911150117432076\n",
      "[-0.74323899] [-0.00413233] 0.40111501174320763\n",
      "[-0.73653119] [0.00052147] 0.41111501174320764\n",
      "[-0.74206419] [-0.00947853] 0.40111501174320763\n",
      "[-0.74649159] [-0.01539903] 0.3911150117432076\n",
      "[-0.75142949] [-0.02082163] 0.3811150117432076\n",
      "[-0.75601239] [-0.02546263] 0.3711150117432076\n",
      "[-0.76046799] [-0.03126173] 0.3611150117432076\n",
      "[-0.75266289] [-0.03189842] 0.3711150117432076\n",
      "[-0.74757069] [-0.02837282] 0.3811150117432076\n",
      "[-0.74260689] [-0.02383442] 0.3911150117432076\n",
      "[-0.73561619] [-0.02010372] 0.40111501174320763\n",
      "[-0.72890839] [-0.01544992] 0.41111501174320764\n",
      "[-0.73333579] [-0.02137042] 0.40111501174320763\n",
      "[-0.73827369] [-0.02679302] 0.3911150117432076\n",
      "[-0.74321009] [-0.03241542] 0.3811150117432076\n",
      "[-0.74779299] [-0.03705642] 0.3711150117432076\n",
      "[-0.75224859] [-0.04285552] 0.3611150117432076\n",
      "[-0.74444349] [-0.04349221] 0.3711150117432076\n",
      "[-0.73935129] [-0.03996661] 0.3811150117432076\n",
      "[-0.73438749] [-0.03542821] 0.3911150117432076\n",
      "[-0.72739679] [-0.03169751] 0.40111501174320763\n",
      "[-0.72068899] [-0.02704371] 0.41111501174320764\n",
      "[-0.72511639] [-0.03296421] 0.40111501174320763\n",
      "[-0.73005429] [-0.03838681] 0.3911150117432076\n",
      "[-0.73499069] [-0.04400921] 0.3811150117432076\n",
      "[-0.73957359] [-0.04865021] 0.3711150117432076\n",
      "[-0.74402919] [-0.05444931] 0.3611150117432076\n",
      "[-0.73622409] [-0.055086] 0.3711150117432076\n",
      "[-0.73113189] [-0.0515604] 0.3811150117432076\n",
      "[-0.72616809] [-0.047022] 0.3911150117432076\n",
      "[-0.71917739] [-0.0432913] 0.40111501174320763\n",
      "[-0.71246959] [-0.0386375] 0.41111501174320764\n",
      "[-0.70701689] [-0.0322464] 0.42111501174320765\n",
      "[-0.71144429] [-0.0381669] 0.41111501174320764\n",
      "[-0.71638219] [-0.0435895] 0.40111501174320763\n",
      "[-0.72131859] [-0.0492119] 0.3911150117432076\n",
      "[-0.72590149] [-0.0538529] 0.3811150117432076\n",
      "[-0.73035709] [-0.059652] 0.3711150117432076\n",
      "[-0.72255199] [-0.06028869] 0.3811150117432076\n",
      "[-0.71745979] [-0.05676309] 0.3911150117432076\n",
      "[-0.71046909] [-0.05303239] 0.40111501174320763\n",
      "[-0.70376129] [-0.04837859] 0.41111501174320764\n",
      "[-0.69830859] [-0.04198749] 0.42111501174320765\n",
      "[-0.70273599] [-0.04790799] 0.41111501174320764\n",
      "[-0.70767389] [-0.05333059] 0.40111501174320763\n",
      "[-0.71261029] [-0.05895299] 0.3911150117432076\n",
      "[-0.71719319] [-0.06359399] 0.3811150117432076\n",
      "[-0.72164879] [-0.06939309] 0.3711150117432076\n",
      "[-0.71384369] [-0.07002978] 0.3811150117432076\n",
      "[-0.70875149] [-0.06650418] 0.3911150117432076\n",
      "[-0.70176079] [-0.06277348] 0.40111501174320763\n",
      "[-0.69505299] [-0.05811968] 0.41111501174320764\n",
      "[-0.68960029] [-0.05172858] 0.42111501174320765\n",
      "[-0.69402769] [-0.05764908] 0.41111501174320764\n",
      "[-0.69896559] [-0.06307168] 0.40111501174320763\n",
      "[-0.70390199] [-0.06869408] 0.3911150117432076\n",
      "[-0.70848489] [-0.07333508] 0.3811150117432076\n",
      "[-0.71294049] [-0.07913418] 0.3711150117432076\n",
      "[-0.70513539] [-0.07977087] 0.3811150117432076\n",
      "[-0.70004319] [-0.07624527] 0.3911150117432076\n",
      "[-0.69305249] [-0.07251457] 0.40111501174320763\n",
      "[-0.68634469] [-0.06786077] 0.41111501174320764\n",
      "[-0.68089199] [-0.06146967] 0.42111501174320765\n",
      "[-0.68531939] [-0.06739017] 0.41111501174320764\n",
      "[-0.69025729] [-0.07281277] 0.40111501174320763\n",
      "[-0.69519369] [-0.07843517] 0.3911150117432076\n",
      "[-0.69977659] [-0.08307617] 0.3811150117432076\n",
      "[-0.70423219] [-0.08887527] 0.3711150117432076\n",
      "[-0.69642709] [-0.08951196] 0.3811150117432076\n",
      "[-0.69133489] [-0.08598636] 0.3911150117432076\n",
      "[-0.68434419] [-0.08225566] 0.40111501174320763\n",
      "[-0.67763639] [-0.07760186] 0.41111501174320764\n",
      "[-0.67218369] [-0.07121076] 0.42111501174320765\n",
      "[-0.67661109] [-0.07713126] 0.41111501174320764\n",
      "[-0.68154899] [-0.08255386] 0.40111501174320763\n",
      "[-0.68648539] [-0.08817626] 0.3911150117432076\n",
      "[-0.69106829] [-0.09281726] 0.3811150117432076\n",
      "[-0.69552389] [-0.09861636] 0.3711150117432076\n",
      "[-0.68771879] [-0.09925305] 0.3811150117432076\n",
      "[-0.68262659] [-0.09572745] 0.3911150117432076\n",
      "[-0.67563589] [-0.09199675] 0.40111501174320763\n",
      "[-0.66892809] [-0.08734295] 0.41111501174320764\n",
      "[-0.66347539] [-0.08095185] 0.42111501174320765\n",
      "[-0.66790279] [-0.08687235] 0.41111501174320764\n",
      "[-0.67284069] [-0.09229495] 0.40111501174320763\n",
      "[-0.67777709] [-0.09791735] 0.3911150117432076\n",
      "[-0.68235999] [-0.10255835] 0.3811150117432076\n",
      "[-0.68681559] [-0.10835745] 0.3711150117432076\n",
      "[-0.67901049] [-0.10899414] 0.3811150117432076\n",
      "[-0.67391829] [-0.10546854] 0.3911150117432076\n",
      "[-0.66692759] [-0.10173784] 0.40111501174320763\n",
      "[-0.66021979] [-0.09708404] 0.41111501174320764\n",
      "[-0.65476709] [-0.09069294] 0.42111501174320765\n",
      "[-0.65919449] [-0.09661344] 0.41111501174320764\n",
      "[-0.66413239] [-0.10203604] 0.40111501174320763\n",
      "[-0.66906879] [-0.10765844] 0.3911150117432076\n",
      "[-0.67365169] [-0.11229944] 0.3811150117432076\n",
      "[-0.67810729] [-0.11809854] 0.3711150117432076\n",
      "[-0.67030219] [-0.11873523] 0.3811150117432076\n",
      "[-0.66520999] [-0.11520963] 0.3911150117432076\n",
      "[-0.65821929] [-0.11147893] 0.40111501174320763\n",
      "[-0.65151149] [-0.10682513] 0.41111501174320764\n",
      "[-0.64605879] [-0.10043403] 0.42111501174320765\n",
      "[-0.65048619] [-0.10635453] 0.41111501174320764\n",
      "[-0.65542409] [-0.11177713] 0.40111501174320763\n",
      "[-0.66036049] [-0.11739953] 0.3911150117432076\n",
      "[-0.66494339] [-0.12204053] 0.3811150117432076\n",
      "[-0.66939899] [-0.12783963] 0.3711150117432076\n",
      "[-0.66159389] [-0.12847632] 0.3811150117432076\n",
      "[-0.65650169] [-0.12495072] 0.3911150117432076\n",
      "[-0.64951099] [-0.12122002] 0.40111501174320763\n",
      "[-0.64280319] [-0.11656622] 0.41111501174320764\n",
      "[-0.63735049] [-0.11017512] 0.42111501174320765\n",
      "[-0.64177789] [-0.11609562] 0.41111501174320764\n",
      "[-0.64671579] [-0.12151822] 0.40111501174320763\n",
      "[-0.65165219] [-0.12714062] 0.3911150117432076\n",
      "[-0.65623509] [-0.13178162] 0.3811150117432076\n",
      "[-0.66069069] [-0.13758072] 0.3711150117432076\n",
      "[-0.65288559] [-0.13821741] 0.3811150117432076\n",
      "[-0.64779339] [-0.13469181] 0.3911150117432076\n",
      "[-0.64080269] [-0.13096111] 0.40111501174320763\n",
      "[-0.63409489] [-0.12630731] 0.41111501174320764\n",
      "[-0.62864219] [-0.11991621] 0.42111501174320765\n",
      "[-0.63306959] [-0.12583671] 0.41111501174320764\n",
      "[-0.63800749] [-0.13125931] 0.40111501174320763\n",
      "[-0.64294389] [-0.13688171] 0.3911150117432076\n",
      "[-0.64752679] [-0.14152271] 0.3811150117432076\n",
      "[-0.65198239] [-0.14732181] 0.3711150117432076\n",
      "[-0.64417729] [-0.1479585] 0.3811150117432076\n",
      "[-0.63921349] [-0.1434201] 0.3911150117432076\n",
      "[-0.63222279] [-0.1396894] 0.40111501174320763\n",
      "[-0.62551499] [-0.1350356] 0.41111501174320764\n",
      "[-0.62006229] [-0.1286445] 0.42111501174320765\n",
      "[-0.62448969] [-0.134565] 0.41111501174320764\n",
      "[-0.62942759] [-0.1399876] 0.40111501174320763\n",
      "[-0.63436399] [-0.14561] 0.3911150117432076\n",
      "[-0.63894689] [-0.150251] 0.3811150117432076\n",
      "[-0.64340249] [-0.1560501] 0.3711150117432076\n",
      "[-0.63559739] [-0.15668679] 0.3811150117432076\n",
      "[-0.63063359] [-0.15214839] 0.3911150117432076\n",
      "[-0.62364289] [-0.14841769] 0.40111501174320763\n",
      "[-0.61693509] [-0.14376389] 0.41111501174320764\n",
      "[-0.61148239] [-0.13737279] 0.42111501174320765\n",
      "[-0.61590979] [-0.14329329] 0.41111501174320764\n",
      "[-0.62084769] [-0.14871589] 0.40111501174320763\n",
      "[-0.62578409] [-0.15433829] 0.3911150117432076\n",
      "[-0.63036699] [-0.15897929] 0.3811150117432076\n",
      "[-0.63482259] [-0.16477839] 0.3711150117432076\n",
      "[-0.62701749] [-0.16541508] 0.3811150117432076\n",
      "[-0.62205369] [-0.16087668] 0.3911150117432076\n",
      "[-0.61506299] [-0.15714598] 0.40111501174320763\n",
      "[-0.60835519] [-0.15249218] 0.41111501174320764\n",
      "[-0.60290249] [-0.14610108] 0.42111501174320765\n",
      "[-0.60732989] [-0.15202158] 0.41111501174320764\n",
      "[-0.61226779] [-0.15744418] 0.40111501174320763\n",
      "[-0.61720419] [-0.16306658] 0.3911150117432076\n",
      "[-0.62178709] [-0.16770758] 0.3811150117432076\n",
      "[-0.62624269] [-0.17350668] 0.3711150117432076\n",
      "[-0.61843759] [-0.17414337] 0.3811150117432076\n",
      "[-0.61347379] [-0.16960497] 0.3911150117432076\n",
      "[-0.60648309] [-0.16587427] 0.40111501174320763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.59977529] [-0.16122047] 0.41111501174320764\n",
      "[-0.59432259] [-0.15482937] 0.42111501174320765\n",
      "[-0.59874999] [-0.16074987] 0.41111501174320764\n",
      "[-0.60368789] [-0.16617247] 0.40111501174320763\n",
      "[-0.60862429] [-0.17179487] 0.3911150117432076\n",
      "[-0.61320719] [-0.17643587] 0.3811150117432076\n",
      "[-0.61766279] [-0.18223497] 0.3711150117432076\n",
      "[-0.60985769] [-0.18287166] 0.3811150117432076\n",
      "[-0.60489389] [-0.17833326] 0.3911150117432076\n",
      "[-0.59790319] [-0.17460256] 0.40111501174320763\n",
      "[-0.59119539] [-0.16994876] 0.41111501174320764\n",
      "[-0.58574269] [-0.16355766] 0.42111501174320765\n",
      "[-0.59017009] [-0.16947816] 0.41111501174320764\n",
      "[-0.59510799] [-0.17490076] 0.40111501174320763\n",
      "[-0.60004439] [-0.18052316] 0.3911150117432076\n",
      "[-0.60462729] [-0.18516416] 0.3811150117432076\n",
      "[-0.60908289] [-0.19096326] 0.3711150117432076\n",
      "[-0.60127779] [-0.19159995] 0.3811150117432076\n",
      "[-0.59631399] [-0.18706155] 0.3911150117432076\n",
      "[-0.58932329] [-0.18333085] 0.40111501174320763\n",
      "[-0.58261549] [-0.17867705] 0.41111501174320764\n",
      "[-0.57716279] [-0.17228595] 0.42111501174320765\n",
      "[-0.58159019] [-0.17820645] 0.41111501174320764\n",
      "[-0.58652809] [-0.18362905] 0.40111501174320763\n",
      "[-0.59146449] [-0.18925145] 0.3911150117432076\n",
      "[-0.59604739] [-0.19389245] 0.3811150117432076\n",
      "[-0.60050299] [-0.19969155] 0.3711150117432076\n",
      "[-0.59269789] [-0.20032824] 0.3811150117432076\n",
      "[-0.58773409] [-0.19578984] 0.3911150117432076\n",
      "[-0.58074339] [-0.19205914] 0.40111501174320763\n",
      "[-0.57403559] [-0.18740534] 0.41111501174320764\n",
      "[-0.56858289] [-0.18101424] 0.42111501174320765\n",
      "[-0.57301029] [-0.18693474] 0.41111501174320764\n",
      "[-0.57794819] [-0.19235734] 0.40111501174320763\n",
      "[-0.58288459] [-0.19797974] 0.3911150117432076\n",
      "[-0.58746749] [-0.20262074] 0.3811150117432076\n",
      "[-0.59192309] [-0.20841984] 0.3711150117432076\n",
      "[-0.58411799] [-0.20905653] 0.3811150117432076\n",
      "[-0.57915419] [-0.20451813] 0.3911150117432076\n",
      "[-0.57216349] [-0.20078743] 0.40111501174320763\n",
      "[-0.56545569] [-0.19613363] 0.41111501174320764\n",
      "[-0.56000299] [-0.18974253] 0.42111501174320765\n",
      "[-0.56443039] [-0.19566303] 0.41111501174320764\n",
      "[-0.56936829] [-0.20108563] 0.40111501174320763\n",
      "[-0.57430469] [-0.20670803] 0.3911150117432076\n",
      "[-0.57888759] [-0.21134903] 0.3811150117432076\n",
      "[-0.58334319] [-0.21714813] 0.3711150117432076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array([0.55152414]), array([-2.13117352])),\n",
       " (array([3.75673789]), array([-3.59593078])),\n",
       " (array([55.12356555]), array([-27.42299077])),\n",
       " (array([-49.0767963]), array([22.27866742])),\n",
       " (array([-24.32584137]), array([11.5513429])),\n",
       " (array([-17.55313]), array([8.42633519])),\n",
       " (array([-13.66461999]), array([6.63213149])),\n",
       " (array([-12.24363032]), array([6.22133349])),\n",
       " (array([-10.39943233]), array([5.34801072])),\n",
       " (array([-9.0092606]), array([4.68969277])),\n",
       " (array([-7.92382577]), array([4.17568345])),\n",
       " (array([-7.05282428]), array([3.76321937])),\n",
       " (array([-6.33842492]), array([3.42491446])),\n",
       " (array([-5.74187677]), array([3.14241817])),\n",
       " (array([-5.23623986]), array([2.90297304])),\n",
       " (array([-4.80220388]), array([2.69743464])),\n",
       " (array([-4.42556584]), array([2.51907712])),\n",
       " (array([-4.12305068]), array([2.37817856])),\n",
       " (array([-3.85258389]), array([2.25220675])),\n",
       " (array([-3.60932889]), array([2.13890902])),\n",
       " (array([-3.38937567]), array([2.03646426])),\n",
       " (array([-3.1895291]), array([1.94338431])),\n",
       " (array([-3.00715266]), array([1.8584412])),\n",
       " (array([-2.84005148]), array([1.78061265])),\n",
       " (array([-2.68638361]), array([1.70904076]))]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPerceptronAlgorithm(x_data, y_data, learn_rate = 0.01, num_epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
